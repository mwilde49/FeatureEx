{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Radiomic Feature Extraction\n",
    "## Extract radiomics features from 3D medical imaging volumes\n",
    "\n",
    "This notebook extracts radiomic features from 3D medical images:\n",
    "- **Input:** Raw 3D NIfTI volumes from imagesTr/labelsTr\n",
    "- **Features:** Shape, Texture (GLCM, GLRLM, GLSZM), Intensity-based radiomic features\n",
    "- **Output:** Feature matrices saved as pickle and CSV\n",
    "- **Multi-class:** Extracts features for each structure separately (classes 1-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n",
    "import logging\n",
    "import warnings\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('radiomics').setLevel(logging.ERROR)\n",
    "\n",
    "print(f\"PyRadiomics version: {radiomics.__version__}\")\n",
    "print(f\"Radiomics successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = Path('C:/FeatureEx')\n",
    "IMAGES_DIR = BASE_DIR / 'imagesTr' / 'imagesTr'\n",
    "LABELS_DIR = BASE_DIR / 'labelsTr' / 'labelsTr'\n",
    "OUTPUT_DIR = BASE_DIR / 'radiomics_3d'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Settings\n",
    "STRUCTURE_CLASSES = [1, 2, 3, 4]  # Classes 1-4 are structures (0 is background)\n",
    "EXTRACT_ALL_CLASSES = True  # Extract combined mask (all non-background)\n",
    "\n",
    "print(f\"Input directories:\")\n",
    "print(f\"  Images: {IMAGES_DIR}\")\n",
    "print(f\"  Labels: {LABELS_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nExtraction settings:\")\n",
    "print(f\"  Structure classes: {STRUCTURE_CLASSES}\")\n",
    "print(f\"  Extract all non-background: {EXTRACT_ALL_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Radiomics Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom parameter file for 3D radiomics\n",
    "params = {\n",
    "    'binWidth': 25,  # 25 HU bin width for CT-like data\n",
    "    'resampledPixelSpacing': None,  # Keep original spacing\n",
    "    'interpolator': 'sitkBSpline',\n",
    "    'label': 1,  # Will be updated per extraction\n",
    "    'imageType': {\n",
    "        'Original': {},\n",
    "        'Wavelet': {'wavelet': 'coif1'},\n",
    "    },\n",
    "    'featureClass': {\n",
    "        'shape': {},\n",
    "        'firstorder': {},\n",
    "        'glcm': {},\n",
    "        'glrlm': {},\n",
    "        'glszm': {},\n",
    "        'ngtdm': {},\n",
    "        'gldm': {},\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Radiomics parameters configured:\")\n",
    "print(f\"  Bin width: {params['binWidth']}\")\n",
    "print(f\"  Image types: {list(params['imageType'].keys())}\")\n",
    "print(f\"  Feature classes: {list(params['featureClass'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get File Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matching image-label pairs\n",
    "image_files = sorted([f for f in IMAGES_DIR.glob('*.nii*')])\n",
    "label_files = sorted([f for f in LABELS_DIR.glob('*.nii*')])\n",
    "\n",
    "# Create mapping\n",
    "image_map = {f.stem: f for f in image_files}\n",
    "label_map = {f.stem: f for f in label_files}\n",
    "\n",
    "# Find matching pairs\n",
    "matching_pairs = set(image_map.keys()) & set(label_map.keys())\n",
    "file_pairs = [(image_map[name], label_map[name]) for name in sorted(matching_pairs)]\n",
    "\n",
    "print(f\"File pairs found: {len(file_pairs)}\")\n",
    "print(f\"\\nFirst 5 pairs:\")\n",
    "for img_path, lbl_path in file_pairs[:5]:\n",
    "    print(f\"  {img_path.name} <-> {lbl_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions for Multi-class Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class_mask(label_data, class_label, structure_classes):\n",
    "    \"\"\"\n",
    "    Create binary mask for a specific class.\n",
    "    \n",
    "    Args:\n",
    "        label_data: 3D label array\n",
    "        class_label: Label value to extract (int or None for all structures)\n",
    "        structure_classes: List of structure class labels\n",
    "    \n",
    "    Returns:\n",
    "        Binary mask array\n",
    "    \"\"\"\n",
    "    if class_label is None:\n",
    "        # Create mask for all non-background classes\n",
    "        mask = np.isin(label_data, structure_classes).astype(np.uint8)\n",
    "    else:\n",
    "        # Create mask for specific class\n",
    "        mask = (label_data == class_label).astype(np.uint8)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def validate_mask(mask_data, min_voxels=100):\n",
    "    \"\"\"\n",
    "    Validate mask has sufficient voxels.\n",
    "    \n",
    "    Args:\n",
    "        mask_data: Binary mask array\n",
    "        min_voxels: Minimum required voxels\n",
    "    \n",
    "    Returns:\n",
    "        Boolean indicating validity\n",
    "    \"\"\"\n",
    "    voxel_count = np.count_nonzero(mask_data)\n",
    "    return voxel_count >= min_voxels\n",
    "\n",
    "print(\"Mask helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Radiomics Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_class(image_path, label_path, class_label, extractor, structure_classes):\n",
    "    \"\"\"\n",
    "    Extract radiomics features for a specific class.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image NIfTI\n",
    "        label_path: Path to label NIfTI\n",
    "        class_label: Class to extract (or None for all structures)\n",
    "        extractor: RadiomicsFeatureExtractor instance\n",
    "        structure_classes: List of structure class labels\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of features or None if extraction failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        image_nib = nib.load(image_path)\n",
    "        image_array = image_nib.get_fdata()\n",
    "        \n",
    "        label_nib = nib.load(label_path)\n",
    "        label_array = label_nib.get_fdata()\n",
    "        \n",
    "        # Create binary mask for this class\n",
    "        mask_array = create_class_mask(label_array, class_label, structure_classes)\n",
    "        \n",
    "        # Validate mask\n",
    "        if not validate_mask(mask_array):\n",
    "            return None\n",
    "        \n",
    "        # Save mask to temporary NIfTI\n",
    "        mask_nib = nib.Nifti1Image(mask_array.astype(np.uint8), label_nib.affine)\n",
    "        mask_path = Path('/tmp/temp_mask.nii.gz')\n",
    "        nib.save(mask_nib, mask_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extractor.execute(str(image_path), str(mask_path))\n",
    "        \n",
    "        # Clean up temp file\n",
    "        mask_path.unlink(missing_ok=True)\n",
    "        \n",
    "        return dict(features)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"Feature extraction function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Features from All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "# Initialize storage\n",
    "all_features = defaultdict(list)  # {class_label: [features_dict, ...]}\n",
    "feature_names = None\n",
    "sample_ids = []  # Track which sample each feature comes from\n",
    "extraction_log = []\n",
    "\n",
    "print(f\"Starting feature extraction from {len(file_pairs)} image-label pairs...\\n\")\n",
    "\n",
    "# Extract features from each pair\n",
    "for pair_idx, (img_path, lbl_path) in enumerate(tqdm(file_pairs), 1):\n",
    "    sample_name = img_path.stem\n",
    "    log_entry = {'sample': sample_name, 'status': 'success', 'classes_extracted': []}\n",
    "    \n",
    "    # Extract for all non-background classes\n",
    "    for class_label in STRUCTURE_CLASSES:\n",
    "        features_dict = extract_features_for_class(\n",
    "            img_path, lbl_path, class_label, extractor, STRUCTURE_CLASSES\n",
    "        )\n",
    "        \n",
    "        if features_dict:\n",
    "            # Store features\n",
    "            all_features[class_label].append(features_dict)\n",
    "            log_entry['classes_extracted'].append(class_label)\n",
    "            \n",
    "            # Extract feature names from first successful extraction\n",
    "            if feature_names is None:\n",
    "                feature_names = list(features_dict.keys())\n",
    "    \n",
    "    # Extract combined mask (all structures together)\n",
    "    if EXTRACT_ALL_CLASSES:\n",
    "        features_dict = extract_features_for_class(\n",
    "            img_path, lbl_path, None, extractor, STRUCTURE_CLASSES\n",
    "        )\n",
    "        if features_dict:\n",
    "            all_features['all_structures'].append(features_dict)\n",
    "            log_entry['classes_extracted'].append('all_structures')\n",
    "    \n",
    "    extraction_log.append(log_entry)\n",
    "    sample_ids.append(sample_name)\n\nprint(f\"\\nFeature extraction complete!\")\nprint(f\"Total feature types: {len(feature_names) if feature_names else 0}\")\nprint(f\"\\nFeatures extracted per class:\")\nfor class_label in STRUCTURE_CLASSES + ['all_structures']:\n",
    "    count = len(all_features[class_label])\n",
    "    print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convert to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for each class\n",
    "feature_dfs = {}\n",
    "\n",
    "for class_label in STRUCTURE_CLASSES + (['all_structures'] if EXTRACT_ALL_CLASSES else []):\n",
    "    if all_features[class_label]:\n",
    "        df = pd.DataFrame(all_features[class_label])\n",
    "        feature_dfs[f'class_{class_label}'] = df\n",
    "        \n",
    "        print(f\"\\nClass {class_label}:\")\n",
    "        print(f\"  Samples: {len(df)}\")\n",
    "        print(f\"  Features: {len(df.columns)}\")\n",
    "        print(f\"  Shape: {df.shape}\")\n",
    "        print(f\"  Sample columns: {list(df.columns[:5])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Combine and Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create combined feature matrix (all classes concatenated)\n",
    "combined_features_list = []\n",
    "class_labels_list = []\n",
    "sample_ids_combined = []\n",
    "\n",
    "for class_idx, class_label in enumerate(STRUCTURE_CLASSES):\n",
    "    df_key = f'class_{class_label}'\n",
    "    if df_key in feature_dfs:\n",
    "        df = feature_dfs[df_key]\n",
    "        combined_features_list.append(df.values)\n",
    "        class_labels_list.extend([class_label] * len(df))\n",
    "        sample_ids_combined.extend(df.index.tolist())\n",
    "\n",
    "# Combine and create DataFrame\n",
    "if combined_features_list:\n",
    "    combined_array = np.vstack(combined_features_list)\n",
    "    combined_df = pd.DataFrame(\n",
    "        combined_array,\n",
    "        columns=feature_names if feature_names else [f'feature_{i}' for i in range(combined_array.shape[1])]\n",
    "    )\n",
    "    combined_df['class'] = class_labels_list\n",
    "    \n",
    "    print(f\"Combined feature matrix:\")\n",
    "    print(f\"  Shape: {combined_df.shape}\")\n",
    "    print(f\"  Samples: {len(combined_df)}\")\n",
    "    print(f\"  Features: {len(feature_names) if feature_names else 0}\")\n",
    "    \n",
    "    # Show class distribution\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    for class_label in STRUCTURE_CLASSES:\n",
    "        count = (combined_df['class'] == class_label).sum()\n",
    "        print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Statistics and Summary"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 9. Feature Statistics and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "if feature_names:\n",
    "    print(f\"Feature statistics (combined data):\")\n",
    "    print(f\"\\nTop 10 features by variance:\")\n",
    "    \n",
    "    feature_variance = combined_df[feature_names].var()\n",
    "    top_features = feature_variance.nlargest(10)\n",
    "    \n",
    "    for idx, (feat_name, variance) in enumerate(top_features.items(), 1):\n",
    "        print(f\"  {idx}. {feat_name}: {variance:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFeature summary:\")\n",
    "    print(f\"  Mean features per sample: {len(feature_names)}\")\n",
    "    print(f\"  Total features: {len(feature_names) * len(combined_df)}\")\n",
    "    print(f\"  Data types represented: {len(set([feat.split('_')[0] for feat in feature_names]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Features to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save individual class features as CSV\n",
    "for class_label in STRUCTURE_CLASSES:\n",
    "    df_key = f'class_{class_label}'\n",
    "    if df_key in feature_dfs:\n",
    "        output_path = OUTPUT_DIR / f'radiomics_3d_class_{class_label}.csv'\n",
    "        feature_dfs[df_key].to_csv(output_path, index=True)\n",
    "        print(f\"Saved: {output_path.name}\")\n",
    "\n",
    "# Save combined features\n",
    "if len(combined_features_list) > 0:\n",
    "    combined_csv_path = OUTPUT_DIR / 'radiomics_3d_combined.csv'\n",
    "    combined_df.to_csv(combined_csv_path, index=True)\n",
    "    print(f\"Saved: {combined_csv_path.name}\")\n",
    "\n",
    "# Save all-structures features\n",
    "if EXTRACT_ALL_CLASSES and 'all_structures' in feature_dfs:\n",
    "    all_struct_path = OUTPUT_DIR / 'radiomics_3d_all_structures.csv'\n",
    "    feature_dfs['all_structures'].to_csv(all_struct_path, index=True)\n",
    "    print(f\"Saved: {all_struct_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Features as Pickle (for sklearn compatibility)"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 11. Save Features as Pickle (for sklearn compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle for later use with sklearn\n",
    "pickle_data = {\n",
    "    'feature_dfs': feature_dfs,\n",
    "    'combined_df': combined_df if len(combined_features_list) > 0 else None,\n",
    "    'feature_names': feature_names,\n",
    "    'structure_classes': STRUCTURE_CLASSES,\n",
    "    'metadata': {\n",
    "        'total_samples': len(file_pairs),\n",
    "        'total_features': len(feature_names) if feature_names else 0,\n",
    "        'classes': STRUCTURE_CLASSES,\n",
    "        'extraction_log': extraction_log\n",
    "    }\n",
    "}\n",
    "\n",
    "pickle_path = OUTPUT_DIR / 'radiomics_3d_features.pkl'\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(pickle_data, f)\n",
    "\n",
    "print(f\"\\nSaved pickle: {pickle_path.name}\")\n",
    "print(f\"Pickle contains:\")\n",
    "print(f\"  - Feature DataFrames for each class\")\n",
    "print(f\"  - Combined DataFrame\")\n",
    "print(f\"  - Feature names\")\n",
    "print(f\"  - Metadata and extraction log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Create Configuration Summary"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 12. Create Configuration Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_summary = {\n",
    "    'extraction_info': {\n",
    "        'total_samples': len(file_pairs),\n",
    "        'successful_extractions': sum(len(features) for features in all_features.values()),\n",
    "        'extraction_log_path': str(OUTPUT_DIR / 'extraction_log.json')\n",
    "    },\n",
    "    'features': {\n",
    "        'total_feature_types': len(feature_names) if feature_names else 0,\n",
    "        'feature_names': feature_names[:10] if feature_names else [],\n",
    "        'num_features_truncated': len(feature_names) - 10 if feature_names and len(feature_names) > 10 else 0\n",
    "    },\n",
    "    'classes': {\n",
    "        'structure_classes': STRUCTURE_CLASSES,\n",
    "        'num_structures': len(STRUCTURE_CLASSES),\n",
    "        'include_all_structures': EXTRACT_ALL_CLASSES\n",
    "    },\n",
    "    'data_distribution': {\n",
    "        f'class_{cls}': len(all_features[cls]) for cls in STRUCTURE_CLASSES\n",
    "    },\n",
    "    'output_files': {\n",
    "        'pickle': 'radiomics_3d_features.pkl',\n",
    "        'combined_csv': 'radiomics_3d_combined.csv',\n",
    "        'individual_csvs': [f'radiomics_3d_class_{cls}.csv' for cls in STRUCTURE_CLASSES],\n",
    "        'config_summary': 'radiomics_3d_config.json',\n",
    "        'extraction_log': 'extraction_log.json'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "config_path = OUTPUT_DIR / 'radiomics_3d_config.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config_summary, f, indent=2)\n",
    "\n",
    "print(f\"Configuration summary:\")\n",
    "for key, val in config_summary.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    if isinstance(val, dict):\n",
    "        for k, v in val.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"  {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Extraction Log"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 13. Save Extraction Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed extraction log\n",
    "log_path = OUTPUT_DIR / 'extraction_log.json'\n",
    "with open(log_path, 'w') as f:\n",
    "    json.dump(extraction_log, f, indent=2)\n",
    "\n",
    "print(f\"Extraction log saved to: {log_path.name}\")\n",
    "\n",
    "# Print summary\n",
    "successful = sum(1 for entry in extraction_log if entry['classes_extracted'])\n",
    "print(f\"\\nExtraction summary:\")\n",
    "print(f\"  Total samples processed: {len(extraction_log)}\")\n",
    "print(f\"  Successful: {successful}\")\n",
    "print(f\"  Success rate: {(successful/len(extraction_log))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 14. Load and Verify Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the pickle file\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "print(f\"Verification - Loaded pickle contents:\")\n",
    "print(f\"  Keys: {list(loaded_data.keys())}\")\n",
    "print(f\"  Feature DataFrames: {list(loaded_data['feature_dfs'].keys())}\")\n",
    "print(f\"  Number of features: {len(loaded_data['feature_names'])}\")\n",
    "print(f\"  Structure classes: {loaded_data['metadata']['structure_classes']}\")\n",
    "\n",
    "if loaded_data['combined_df'] is not None:\n",
    "    print(f\"\\nCombined DataFrame shape: {loaded_data['combined_df'].shape}\")\n",
    "    print(f\"Column names (first 5): {list(loaded_data['combined_df'].columns[:5])}\")"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 15. Feature Usage Example"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 15. Feature Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using extracted features for classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Example: Classification using radiomic features\\n\")\n",
    "\n",
    "if loaded_data['combined_df'] is not None:\n",
    "    combined = loaded_data['combined_df']\n",
    "    \n",
    "    # Separate features and labels\n",
    "    X = combined[loaded_data['feature_names']].values\n",
    "    y = combined['class'].values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Classification Results:\")\n",
    "    print(f\"  Training samples: {len(X_train)}\")\n",
    "    print(f\"  Test samples: {len(X_test)}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nPer-class accuracy:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(f\"\\nTop 10 most important features:\")\n",
    "    importances = clf.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': loaded_data['feature_names'],\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    for idx, row in feature_importance_df.head(10).iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.6f}\")"
   ]
  },
  {
   "cell_type": {"text": "markdown"}, "source": [
    "## 16. Summary and Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3D RADIOMIC FEATURE EXTRACTION - COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nOutput Directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nGenerated Files:\")\n",
    "\n",
    "output_files = list(OUTPUT_DIR.glob('*'))\n",
    "for file in sorted(output_files):\n",
    "    size_mb = file.stat().st_size / (1024*1024)\n",
    "    print(f\"  - {file.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(f\"\\nExtraction Summary:\")\n",
    "print(f\"  Total samples: {len(file_pairs)}\")\n",
    "print(f\"  Features per structure: {len(feature_names) if feature_names else 0}\")\n",
    "print(f\"  Classes: {STRUCTURE_CLASSES}\")\n",
    "print(f\"  All-structures combined: {EXTRACT_ALL_CLASSES}\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Load features: pickle.load(open('{OUTPUT_DIR / 'radiomics_3d_features.pkl'}', 'rb'))\")\n",
    "print(f\"  2. Access combined features: loaded_data['combined_df']\")\n",
    "print(f\"  3. Use for classification: X = combined_df[feature_names], y = combined_df['class']\")\n",
    "print(f\"  4. Fuse with CNN features for multi-modal analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
