{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Labels from Stulberg Classification\n",
    "## Extract and match Stulberg labels with existing classification metadata\n",
    "\n",
    "This notebook:\n",
    "- Loads Stulberg classification data from second sheet\n",
    "- Parses image filenames to extract patient number, view, and side\n",
    "- Filters for AP (anterior-posterior) view images only\n",
    "- Matches with existing classification_metadata.xlsx\n",
    "- Creates updated classification_metadata2.xlsx with matched entries only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "BASE_DIR = Path('C:/FeatureEx')\n",
    "STULBERG_FILE = BASE_DIR / 'Stulberg classification.xlsx'\n",
    "METADATA_FILE = BASE_DIR / 'classification_metadata.xlsx'\n",
    "OUTPUT_FILE = BASE_DIR / 'classification_metadata2.xlsx'\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Input files:\")\n",
    "print(f\"  Stulberg: {STULBERG_FILE}\")\n",
    "print(f\"  Metadata: {METADATA_FILE}\")\n",
    "print(f\"\\nOutput file:\")\n",
    "print(f\"  {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Stulberg Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Stulberg classification from second sheet\n",
    "print(\"Loading Stulberg classification data...\")\n",
    "\n",
    "# First, let's check what sheets are available\n",
    "xls = pd.ExcelFile(STULBERG_FILE)\n",
    "print(f\"\\nAvailable sheets in Stulberg classification.xlsx:\")\n",
    "for i, sheet in enumerate(xls.sheet_names):\n",
    "    print(f\"  {i}: {sheet}\")\n",
    "\n",
    "# Load the second sheet (index 1)\n",
    "stulberg_df = pd.read_excel(STULBERG_FILE, sheet_name=1)\n",
    "\n",
    "print(f\"\\nStulberg data shape: {stulberg_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(stulberg_df.head(10))\n",
    "\n",
    "print(f\"\\nColumn names:\")\n",
    "print(stulberg_df.columns.tolist())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(stulberg_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse Image Filenames to Extract Patient, View, and Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from image filenames\n",
    "print(\"Parsing image filenames to extract patient number, view, and side...\\n\")\n",
    "\n",
    "def parse_image_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse image filename in format: Patient_X_VIEW_..._SIDE.bmp\n",
    "    Example: Patient_1_AP_..._R.bmp\n",
    "    \n",
    "    Returns: {'patient_number': str, 'view': str, 'side': str}\n",
    "    \"\"\"\n",
    "    if pd.isna(filename) or not isinstance(filename, str):\n",
    "        return {'patient_number': None, 'view': None, 'side': None}\n",
    "    \n",
    "    filename = filename.strip()\n",
    "    \n",
    "    # Pattern: Patient_X_VIEW_..._SIDE.bmp\n",
    "    # We need to extract:\n",
    "    # 1. Patient number: after 'Patient_' up to the next underscore\n",
    "    # 2. View: the next component (AP, LAT, PA, etc.)\n",
    "    # 3. Side: the last character before .bmp extension (L or R)\n",
    "    \n",
    "    try:\n",
    "        # Remove .bmp extension\n",
    "        name_no_ext = filename.replace('.bmp', '').replace('.BMP', '')\n",
    "        \n",
    "        # Split by underscore\n",
    "        parts = name_no_ext.split('_')\n",
    "        \n",
    "        if len(parts) >= 3:\n",
    "            # parts[0] = 'Patient'\n",
    "            # parts[1] = patient number\n",
    "            # parts[2] = view (AP, LAT, PA, etc.)\n",
    "            # parts[-1] = side (L or R)\n",
    "            \n",
    "            patient_num = parts[1]  # e.g., '1', '1008', etc.\n",
    "            view = parts[2]         # e.g., 'AP', 'LAT', 'PA'\n",
    "            side = parts[-1]        # e.g., 'L', 'R'\n",
    "            \n",
    "            return {\n",
    "                'patient_number': patient_num,\n",
    "                'view': view,\n",
    "                'side': side\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing '{filename}': {e}\")\n",
    "    \n",
    "    return {'patient_number': None, 'view': None, 'side': None}\n",
    "\n",
    "\n",
    "# Apply parsing to first column (image filename column)\n",
    "first_col = stulberg_df.iloc[:, 0]  # Get the first column\n",
    "print(f\"Sample filenames from first column:\")\n",
    "print(first_col.head(10).tolist())\n",
    "\n",
    "# Parse all filenames\n",
    "parsed_data = first_col.apply(parse_image_filename).apply(pd.Series)\n",
    "\n",
    "print(f\"\\nParsed data (first 10 rows):\")\n",
    "print(parsed_data.head(10))\n",
    "\n",
    "# Add parsed columns to dataframe\n",
    "stulberg_df['patient_number'] = parsed_data['patient_number']\n",
    "stulberg_df['view'] = parsed_data['view']\n",
    "stulberg_df['side'] = parsed_data['side']\n",
    "\n",
    "print(f\"\\nStulberg data with parsed columns:\")\n",
    "print(stulberg_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filter for AP View Images Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for AP view images only\n",
    "print(\"Filtering for AP view images only...\\n\")\n",
    "\n",
    "print(f\"View distribution in original data:\")\n",
    "print(stulberg_df['view'].value_counts())\n",
    "\n",
    "# Filter for AP images\n",
    "stulberg_ap_df = stulberg_df[stulberg_df['view'] == 'AP'].copy()\n",
    "\n",
    "print(f\"\\nAP images only:\")\n",
    "print(f\"  Total rows: {len(stulberg_ap_df)}\")\n",
    "print(f\"\\nFirst few AP entries:\")\n",
    "print(stulberg_ap_df.head(10))\n",
    "\n",
    "# Display relevant columns\n",
    "print(f\"\\nRelevant columns:\")\n",
    "print(stulberg_ap_df[['patient_number', 'view', 'side', 'Alex']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Classification Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing classification metadata\n",
    "print(\"Loading classification_metadata.xlsx...\\n\")\n",
    "\n",
    "metadata_df = pd.read_excel(METADATA_FILE, sheet_name='samples')\n",
    "\n",
    "print(f\"Metadata shape: {metadata_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(metadata_df.head(10))\n",
    "\n",
    "print(f\"\\nColumn names:\")\n",
    "print(metadata_df.columns.tolist())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(metadata_df.dtypes)\n",
    "\n",
    "print(f\"\\nFirst column (sample_id) sample values:\")\n",
    "print(metadata_df.iloc[:, 0].head(15).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Matching Key for Stulberg Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matching key in format: 'Patient XXXX Side' or 'Patient X Side'\n",
    "print(\"Creating matching keys for AP images...\\n\")\n",
    "\n",
    "def create_patient_side_key(row):\n",
    "    \"\"\"\n",
    "    Create matching key in format: 'Patient XXXX Side'\n",
    "    Example: 'Patient 1008 Right' or 'Patient 99 Left'\n",
    "    \"\"\"\n",
    "    patient_num = row['patient_number']\n",
    "    side = row['side']\n",
    "    \n",
    "    if pd.isna(patient_num) or pd.isna(side):\n",
    "        return None\n",
    "    \n",
    "    # Convert side (L/R to Left/Right)\n",
    "    side_full = 'Right' if side == 'R' else 'Left' if side == 'L' else None\n",
    "    \n",
    "    if side_full is None:\n",
    "        return None\n",
    "    \n",
    "    return f\"Patient {patient_num} {side_full}\"\n",
    "\n",
    "# Apply to AP filtered data\n",
    "stulberg_ap_df['match_key'] = stulberg_ap_df.apply(create_patient_side_key, axis=1)\n",
    "\n",
    "print(f\"Sample match keys:\")\n",
    "print(stulberg_ap_df[['patient_number', 'side', 'match_key']].head(15))\n",
    "\n",
    "print(f\"\\nMatch key statistics:\")\n",
    "print(f\"  Total AP entries: {len(stulberg_ap_df)}\")\n",
    "print(f\"  Valid match keys: {stulberg_ap_df['match_key'].notna().sum()}\")\n",
    "print(f\"  Missing match keys: {stulberg_ap_df['match_key'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parse Classification Metadata Sample IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first column of classification_metadata.xlsx contains sample_id\n",
    "# We need to create a matching key from these\n",
    "print(\"Extracting patient and side info from classification_metadata.xlsx...\\n\")\n",
    "\n",
    "# The first column name\n",
    "id_column = metadata_df.columns[0]\n",
    "print(f\"ID column: '{id_column}'\")\n",
    "\n",
    "# Sample values\n",
    "print(f\"\\nSample ID values:\")\n",
    "print(metadata_df[id_column].unique()[:20])\n",
    "\n",
    "# Create the match key directly from the sample_id\n",
    "# It appears these are already in the format 'Patient XXXX Side' or similar\n",
    "# Let's check if they match our generated keys\n",
    "metadata_df['match_key'] = metadata_df[id_column].str.strip()\n",
    "\n",
    "print(f\"\\nMatch keys from metadata (first 15):\")\n",
    "print(metadata_df['match_key'].head(15).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Match and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge/join\n",
    "print(\"Matching Stulberg AP data with classification_metadata...\\n\")\n",
    "\n",
    "# Create a subset of Stulberg with only relevant columns\n",
    "stulberg_to_merge = stulberg_ap_df[['match_key', 'Alex']].copy()\n",
    "stulberg_to_merge.columns = ['match_key', 'stulberg_label']\n",
    "stulberg_to_merge = stulberg_to_merge[stulberg_to_merge['match_key'].notna()]\n",
    "\n",
    "print(f\"Stulberg AP data to merge:\")\n",
    "print(f\"  Rows: {len(stulberg_to_merge)}\")\n",
    "print(stulberg_to_merge.head(10))\n",
    "\n",
    "print(f\"\\nMetadata match keys:\")\n",
    "print(f\"  Rows: {len(metadata_df)}\")\n",
    "print(metadata_df[['match_key']].head(10))\n",
    "\n",
    "# Inner join to keep only matching entries\n",
    "merged_df = metadata_df.merge(\n",
    "    stulberg_to_merge,\n",
    "    on='match_key',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\nMerge results:\")\n",
    "print(f\"  Original metadata rows: {len(metadata_df)}\")\n",
    "print(f\"  Stulberg AP rows: {len(stulberg_to_merge)}\")\n",
    "print(f\"  Matched rows: {len(merged_df)}\")\n",
    "\n",
    "print(f\"\\nMerged data (first 10 rows):\")\n",
    "print(merged_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Updated Classification Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output dataframe in the same format as original\n",
    "print(\"Preparing output file...\\n\")\n",
    "\n",
    "# Get all original columns from metadata\n",
    "original_columns = [col for col in metadata_df.columns if col != 'match_key']\n",
    "print(f\"Original columns: {original_columns}\")\n",
    "\n",
    "# Select output columns\n",
    "output_df = merged_df[original_columns].copy()\n",
    "\n",
    "print(f\"\\nOutput dataframe shape: {output_df.shape}\")\n",
    "print(f\"\\nOutput dataframe (first 15 rows):\")\n",
    "print(output_df.head(15))\n",
    "\n",
    "print(f\"\\nOutput dataframe columns:\")\n",
    "print(output_df.columns.tolist())\n",
    "\n",
    "print(f\"\\nOutput statistics:\")\n",
    "print(output_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel\n",
    "print(\"Exporting to classification_metadata2.xlsx...\\n\")\n",
    "\n",
    "# Save with the same sheet name as original\n",
    "output_df.to_excel(OUTPUT_FILE, sheet_name='samples', index=False)\n",
    "\n",
    "print(f\"Successfully saved to: {OUTPUT_FILE}\")\n",
    "print(f\"\\nFile statistics:\")\n",
    "print(f\"  Rows: {len(output_df)}\")\n",
    "print(f\"  Columns: {len(output_df.columns)}\")\n",
    "\n",
    "# Verify the output\n",
    "verification_df = pd.read_excel(OUTPUT_FILE, sheet_name='samples')\n",
    "print(f\"\\nVerification - Read back from file:\")\n",
    "print(f\"  Shape: {verification_df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(verification_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LABEL UPDATE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. INPUT DATA\")\n",
    "print(f\"   - Stulberg classification file: {STULBERG_FILE.name}\")\n",
    "print(f\"   - Total rows in Stulberg sheet 2: {len(stulberg_df)}\")\n",
    "print(f\"   - AP view images extracted: {len(stulberg_ap_df)}\")\n",
    "print(f\"   - Valid match keys created: {stulberg_ap_df['match_key'].notna().sum()}\")\n",
    "\n",
    "print(f\"\\n2. ORIGINAL METADATA\")\n",
    "print(f\"   - Original file: {METADATA_FILE.name}\")\n",
    "print(f\"   - Total entries: {len(metadata_df)}\")\n",
    "\n",
    "print(f\"\\n3. MATCHING RESULTS\")\n",
    "print(f\"   - Entries found in both files: {len(output_df)}\")\n",
    "print(f\"   - Match percentage: {len(output_df) / len(metadata_df) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n4. OUTPUT FILE\")\n",
    "print(f\"   - Filename: {OUTPUT_FILE.name}\")\n",
    "print(f\"   - Location: {OUTPUT_FILE}\")\n",
    "print(f\"   - Rows: {len(output_df)}\")\n",
    "print(f\"   - Columns: {len(output_df.columns)}\")\n",
    "\n",
    "print(f\"\\n5. COLUMNS IN OUTPUT\")\n",
    "for col in output_df.columns:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
