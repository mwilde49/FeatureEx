{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline for Medical Image Analysis\n",
    "\n",
    "This notebook performs inference on new images using:\n",
    "1. CNN features (ResNet18)\n",
    "2. Radiomics features\n",
    "3. Fusion features (CNN + Radiomics)\n",
    "\n",
    "Results are saved to `inference/jobs.xlsx` with two sheets:\n",
    "- `predictions`: Image predictions from each model\n",
    "- `feature_scores`: Extracted feature vectors for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Import Libraries\n",
    "# ========================\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import SimpleITK as sitk\n",
    "from radiomics import featureextractor\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('radiomics').setLevel(logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference directory: C:\\FeatureEx\\inference\n",
      "Done directory: C:\\FeatureEx\\inference\\done\n",
      "Jobs file: C:\\FeatureEx\\inference\\jobs.xlsx\n",
      "\n",
      "Directories ready!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Setup Directories and Paths\n",
    "# ========================\n",
    "BASE_DIR = Path(r'C:/FeatureEx')\n",
    "INFERENCE_DIR = BASE_DIR / 'inference'\n",
    "DONE_DIR = INFERENCE_DIR / 'done'\n",
    "MASKS_DIR = BASE_DIR / 'masks'\n",
    "JOBS_FILE = INFERENCE_DIR / 'jobs.xlsx'\n",
    "MODEL_PATH = BASE_DIR / 'best_resnet_model.pth'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "INFERENCE_DIR.mkdir(exist_ok=True)\n",
    "DONE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Inference directory: {INFERENCE_DIR}\")\n",
    "print(f\"Done directory: {DONE_DIR}\")\n",
    "print(f\"Jobs file: {JOBS_FILE}\")\n",
    "print(f\"\\nDirectories ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs file already exists: C:\\FeatureEx\\inference\\jobs.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Initialize Excel File\n",
    "# ========================\n",
    "def initialize_jobs_file():\n",
    "    \"\"\"Create jobs.xlsx with two sheets if it doesn't exist\"\"\"\n",
    "    if not JOBS_FILE.exists():\n",
    "        # Create predictions sheet\n",
    "        predictions_df = pd.DataFrame(columns=[\n",
    "            'filename', 'timestamp', 'cnn_prediction', \n",
    "            'radiomic_prediction', 'fusion_prediction'\n",
    "        ])\n",
    "        \n",
    "        # Create feature_scores sheet (will be dynamically sized)\n",
    "        feature_scores_df = pd.DataFrame(columns=['filename'])\n",
    "        \n",
    "        # Write to Excel\n",
    "        with pd.ExcelWriter(JOBS_FILE, engine='openpyxl') as writer:\n",
    "            predictions_df.to_excel(writer, sheet_name='predictions', index=False)\n",
    "            feature_scores_df.to_excel(writer, sheet_name='feature_scores', index=False)\n",
    "        \n",
    "        print(f\"Created new jobs file: {JOBS_FILE}\")\n",
    "    else:\n",
    "        print(f\"Jobs file already exists: {JOBS_FILE}\")\n",
    "\n",
    "initialize_jobs_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet model class defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Define ResNet Model\n",
    "# ========================\n",
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-based model for classification and feature extraction.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3, feature_dim=512, pretrained=True):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Modify first conv layer for grayscale (1 channel) input\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Remove the original fully connected layer\n",
    "        num_features = self.resnet.fc.in_features  # 512 for ResNet18\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # Custom feature extraction and classification layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(num_features, feature_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(feature_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features using ResNet backbone\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "        # Extract custom features\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        return logits, features\n",
    "\n",
    "print(\"ResNet model class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded CNN model from C:\\FeatureEx\\best_resnet_model.pth\n",
      "  - Validation accuracy: 100.00%\n",
      "\n",
      "CNN model ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Load Trained Models\n",
    "# ========================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load CNN model\n",
    "cnn_model = ResNetFeatureExtractor(num_classes=3, feature_dim=512, pretrained=False)\n",
    "\n",
    "if MODEL_PATH.exists():\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    cnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded CNN model from {MODEL_PATH}\")\n",
    "    print(f\"  - Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "else:\n",
    "    print(f\"WARNING: Model file not found at {MODEL_PATH}\")\n",
    "    print(\"Please train the model first using Test_FE_PCA.ipynb\")\n",
    "\n",
    "cnn_model = cnn_model.to(device)\n",
    "cnn_model.eval()\n",
    "\n",
    "print(\"\\nCNN model ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained classifiers...\n",
      "======================================================================\n",
      "Metadata loaded:\n",
      "  - Fusion type: pca\n",
      "  - CNN features: 512\n",
      "  - Radiomic features: 93\n",
      "\n",
      "✓ CNN classifier loaded\n",
      "✓ Radiomics classifier loaded\n",
      "✓ Fusion classifier loaded\n",
      "\n",
      "Loading PCA preprocessing objects...\n",
      "  ✓ CNN scaler loaded\n",
      "  ✓ Radiomics scaler loaded\n",
      "  ✓ CNN PCA loaded\n",
      "  ✓ Radiomics PCA loaded\n",
      "\n",
      "======================================================================\n",
      "Summary:\n",
      "  CNN classifier: Available\n",
      "  Radiomics classifier: Available\n",
      "  Fusion classifier: Available\n",
      "  Fusion type: pca\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Load Trained Classifiers\n",
    "# ========================\n",
    "import pickle\n",
    "\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "\n",
    "print(\"Loading trained classifiers...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = MODELS_DIR / 'metadata.pkl'\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    print(f\"Metadata loaded:\")\n",
    "    print(f\"  - Fusion type: {metadata.get('fusion_type', 'unknown')}\")\n",
    "    print(f\"  - CNN features: {metadata.get('cnn_features_dim', 'N/A')}\")\n",
    "    print(f\"  - Radiomic features: {metadata.get('radio_features_dim', 'N/A')}\")\n",
    "    fusion_type = metadata.get('fusion_type', 'none')\n",
    "else:\n",
    "    print(\"⚠ Warning: metadata.pkl not found\")\n",
    "    fusion_type = 'none'\n",
    "\n",
    "print()\n",
    "\n",
    "# Load CNN classifier (for reference, though we use the ResNet model directly)\n",
    "cnn_classifier_path = MODELS_DIR / 'clf_cnn.pkl'\n",
    "if cnn_classifier_path.exists():\n",
    "    with open(cnn_classifier_path, 'rb') as f:\n",
    "        cnn_classifier = pickle.load(f)\n",
    "    print(\"✓ CNN classifier loaded\")\n",
    "else:\n",
    "    cnn_classifier = None\n",
    "    print(\"⚠ CNN classifier not found (will use ResNet model predictions)\")\n",
    "\n",
    "# Load radiomics classifier\n",
    "radiomics_classifier_path = MODELS_DIR / 'clf_radio.pkl'\n",
    "if radiomics_classifier_path.exists():\n",
    "    with open(radiomics_classifier_path, 'rb') as f:\n",
    "        radiomics_classifier = pickle.load(f)\n",
    "    print(\"✓ Radiomics classifier loaded\")\n",
    "else:\n",
    "    radiomics_classifier = None\n",
    "    print(\"⚠ Radiomics classifier not found\")\n",
    "\n",
    "# Load fusion classifier\n",
    "fusion_classifier_path = MODELS_DIR / 'clf_fusion.pkl'\n",
    "if fusion_classifier_path.exists():\n",
    "    with open(fusion_classifier_path, 'rb') as f:\n",
    "        fusion_classifier = pickle.load(f)\n",
    "    print(\"✓ Fusion classifier loaded\")\n",
    "else:\n",
    "    fusion_classifier = None\n",
    "    print(\"⚠ Fusion classifier not found\")\n",
    "\n",
    "# Load preprocessing objects if needed for PCA fusion\n",
    "scaler_cnn = None\n",
    "scaler_radio = None\n",
    "pca_cnn = None\n",
    "pca_radio = None\n",
    "\n",
    "if fusion_type == 'pca':\n",
    "    print(\"\\nLoading PCA preprocessing objects...\")\n",
    "\n",
    "    scaler_cnn_path = MODELS_DIR / 'scaler_cnn.pkl'\n",
    "    if scaler_cnn_path.exists():\n",
    "        with open(scaler_cnn_path, 'rb') as f:\n",
    "            scaler_cnn = pickle.load(f)\n",
    "        print(\"  ✓ CNN scaler loaded\")\n",
    "\n",
    "    scaler_radio_path = MODELS_DIR / 'scaler_radio.pkl'\n",
    "    if scaler_radio_path.exists():\n",
    "        with open(scaler_radio_path, 'rb') as f:\n",
    "            scaler_radio = pickle.load(f)\n",
    "        print(\"  ✓ Radiomics scaler loaded\")\n",
    "\n",
    "    pca_cnn_path = MODELS_DIR / 'pca_cnn.pkl'\n",
    "    if pca_cnn_path.exists():\n",
    "        with open(pca_cnn_path, 'rb') as f:\n",
    "            pca_cnn = pickle.load(f)\n",
    "        print(\"  ✓ CNN PCA loaded\")\n",
    "\n",
    "    pca_radio_path = MODELS_DIR / 'pca_radio.pkl'\n",
    "    if pca_radio_path.exists():\n",
    "        with open(pca_radio_path, 'rb') as f:\n",
    "            pca_radio = pickle.load(f)\n",
    "        print(\"  ✓ Radiomics PCA loaded\")\n",
    "\n",
    "# Initialize radiomics extractor\n",
    "radiomics_extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"Summary:\")\n",
    "print(f\"  CNN classifier: {'Available' if cnn_classifier else 'Using ResNet model'}\")\n",
    "print(f\"  Radiomics classifier: {'Available' if radiomics_classifier else 'Not available'}\")\n",
    "print(f\"  Fusion classifier: {'Available' if fusion_classifier else 'Not available'}\")\n",
    "print(f\"  Fusion type: {fusion_type}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Image Preprocessing Functions\n",
    "# ========================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess image for CNN inference\"\"\"\n",
    "    pil_image = Image.open(image_path).convert('L')\n",
    "    image_tensor = transform(pil_image).unsqueeze(0)\n",
    "    return image_tensor, pil_image\n",
    "\n",
    "def create_mask_for_image(pil_image):\n",
    "    \"\"\"Create binary mask for radiomics extraction\"\"\"\n",
    "    # Convert PIL image to numpy array\n",
    "    img_array = np.array(pil_image.resize((224, 224))).astype(np.float32)\n",
    "    \n",
    "    # Create mask with background border\n",
    "    mask_array = np.ones(img_array.shape, dtype=np.uint8)\n",
    "    mask_array[0, :] = 0\n",
    "    mask_array[-1, :] = 0\n",
    "    mask_array[:, 0] = 0\n",
    "    mask_array[:, -1] = 0\n",
    "    \n",
    "    # Convert to SimpleITK\n",
    "    image_sitk = sitk.GetImageFromArray(img_array)\n",
    "    mask_sitk = sitk.GetImageFromArray(mask_array)\n",
    "    mask_sitk = sitk.Cast(mask_sitk, sitk.sitkUInt8)\n",
    "    mask_sitk.CopyInformation(image_sitk)\n",
    "    \n",
    "    return image_sitk, mask_sitk\n",
    "\n",
    "print(\"Preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Feature Extraction Functions\n",
    "# ========================\n",
    "def extract_cnn_features(image_tensor):\n",
    "    \"\"\"Extract CNN features and prediction\"\"\"\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        logits, features = cnn_model(image_tensor)\n",
    "        prediction = torch.argmax(logits, dim=1).item() + 1  # +1 to match labels 1-3\n",
    "        features_np = features.cpu().numpy().flatten()\n",
    "    return prediction, features_np\n",
    "\n",
    "def extract_radiomics_features(pil_image):\n",
    "    \"\"\"Extract radiomics features and prediction\"\"\"\n",
    "    try:\n",
    "        # Create mask\n",
    "        image_sitk, mask_sitk = create_mask_for_image(pil_image)\n",
    "\n",
    "        # Extract features\n",
    "        result = radiomics_extractor.execute(image_sitk, mask_sitk)\n",
    "\n",
    "        # Filter to only original features\n",
    "        features = {k: v for k, v in result.items() if k.startswith(\"original\")}\n",
    "        feature_vector = np.array([float(v) for v in features.values()])\n",
    "\n",
    "        # Predict using radiomics classifier if available\n",
    "        if radiomics_classifier is not None:\n",
    "            # Labels are 0-2 internally, need to convert to 1-3\n",
    "            prediction = radiomics_classifier.predict([feature_vector])[0] + 1\n",
    "        else:\n",
    "            prediction = None  # No classifier available\n",
    "\n",
    "        return prediction, feature_vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting radiomics features: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_fusion_features(cnn_features, radiomic_features):\n",
    "    \"\"\"Combine CNN and radiomics features for fusion prediction\"\"\"\n",
    "    if cnn_features is None or radiomic_features is None:\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # Check if we need to apply PCA preprocessing\n",
    "        if fusion_type == 'pca' and all([scaler_cnn, scaler_radio, pca_cnn, pca_radio]):\n",
    "            # Apply PCA preprocessing\n",
    "            cnn_scaled = scaler_cnn.transform([cnn_features])\n",
    "            radio_scaled = scaler_radio.transform([radiomic_features])\n",
    "\n",
    "            cnn_pca = pca_cnn.transform(cnn_scaled)\n",
    "            radio_pca = pca_radio.transform(radio_scaled)\n",
    "\n",
    "            # Concatenate PCA features\n",
    "            fusion_features = np.concatenate([cnn_pca.flatten(), radio_pca.flatten()])\n",
    "        else:\n",
    "            # Simple concatenation (no PCA)\n",
    "            fusion_features = np.concatenate([cnn_features, radiomic_features])\n",
    "\n",
    "        # Predict using fusion classifier if available\n",
    "        if fusion_classifier is not None:\n",
    "            # Labels are 0-2 internally, need to convert to 1-3\n",
    "            prediction = fusion_classifier.predict([fusion_features])[0] + 1\n",
    "        else:\n",
    "            prediction = None  # No classifier available\n",
    "\n",
    "        return prediction, fusion_features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fusion prediction: {e}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"Feature extraction functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main inference function defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Main Inference Function\n",
    "# ========================\n",
    "def process_image(image_path):\n",
    "    \"\"\"\n",
    "    Process a single image through the inference pipeline\n",
    "    Returns: dict with predictions and features\n",
    "    \"\"\"\n",
    "    filename = Path(image_path).name\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    print(f\"\\nProcessing: {filename}\")\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image_tensor, pil_image = load_and_preprocess_image(image_path)\n",
    "    \n",
    "    # Extract CNN features and prediction\n",
    "    print(\"  - Extracting CNN features...\")\n",
    "    cnn_pred, cnn_features = extract_cnn_features(image_tensor)\n",
    "    print(f\"    CNN prediction: {cnn_pred}\")\n",
    "    \n",
    "    # Extract radiomics features and prediction\n",
    "    print(\"  - Extracting radiomics features...\")\n",
    "    radiomic_pred, radiomic_features = extract_radiomics_features(pil_image)\n",
    "    if radiomic_pred is not None:\n",
    "        print(f\"    Radiomics prediction: {radiomic_pred}\")\n",
    "    else:\n",
    "        print(\"    Radiomics prediction: N/A (no classifier)\")\n",
    "    \n",
    "    # Extract fusion features and prediction\n",
    "    print(\"  - Extracting fusion features...\")\n",
    "    fusion_pred, fusion_features = extract_fusion_features(cnn_features, radiomic_features)\n",
    "    if fusion_pred is not None:\n",
    "        print(f\"    Fusion prediction: {fusion_pred}\")\n",
    "    else:\n",
    "        print(\"    Fusion prediction: N/A (no classifier)\")\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'filename': filename,\n",
    "        'timestamp': timestamp,\n",
    "        'predictions': {\n",
    "            'cnn': cnn_pred,\n",
    "            'radiomic': radiomic_pred,\n",
    "            'fusion': fusion_pred\n",
    "        },\n",
    "        'features': {\n",
    "            'cnn': cnn_features,\n",
    "            'radiomic': radiomic_features,\n",
    "            'fusion': fusion_features\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Main inference function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel save function defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Save Results to Excel\n",
    "# ========================\n",
    "def save_results_to_excel(results):\n",
    "    \"\"\"\n",
    "    Append results to jobs.xlsx\n",
    "    \"\"\"\n",
    "    # Read existing data\n",
    "    predictions_df = pd.read_excel(JOBS_FILE, sheet_name='predictions')\n",
    "    feature_scores_df = pd.read_excel(JOBS_FILE, sheet_name='feature_scores')\n",
    "    \n",
    "    # Add prediction row\n",
    "    new_prediction = {\n",
    "        'filename': results['filename'],\n",
    "        'timestamp': results['timestamp'],\n",
    "        'cnn_prediction': results['predictions']['cnn'],\n",
    "        'radiomic_prediction': results['predictions']['radiomic'],\n",
    "        'fusion_prediction': results['predictions']['fusion']\n",
    "    }\n",
    "    predictions_df = pd.concat([predictions_df, pd.DataFrame([new_prediction])], ignore_index=True)\n",
    "    \n",
    "    # Add feature scores row\n",
    "    feature_row = {'filename': results['filename']}\n",
    "    \n",
    "    # Add CNN features\n",
    "    if results['features']['cnn'] is not None:\n",
    "        for i, val in enumerate(results['features']['cnn']):\n",
    "            feature_row[f'cnn_feature_{i+1}'] = val\n",
    "    \n",
    "    # Add radiomic features\n",
    "    if results['features']['radiomic'] is not None:\n",
    "        for i, val in enumerate(results['features']['radiomic']):\n",
    "            feature_row[f'radiomic_feature_{i+1}'] = val\n",
    "    \n",
    "    # Add fusion features\n",
    "    if results['features']['fusion'] is not None:\n",
    "        for i, val in enumerate(results['features']['fusion']):\n",
    "            feature_row[f'fusion_feature_{i+1}'] = val\n",
    "    \n",
    "    feature_scores_df = pd.concat([feature_scores_df, pd.DataFrame([feature_row])], ignore_index=True)\n",
    "    \n",
    "    # Write back to Excel\n",
    "    with pd.ExcelWriter(JOBS_FILE, engine='openpyxl', mode='w') as writer:\n",
    "        predictions_df.to_excel(writer, sheet_name='predictions', index=False)\n",
    "        feature_scores_df.to_excel(writer, sheet_name='feature_scores', index=False)\n",
    "    \n",
    "    print(f\"  ✓ Results saved to {JOBS_FILE}\")\n",
    "\n",
    "print(\"Excel save function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move function defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Move Processed Image\n",
    "# ========================\n",
    "def move_to_done(image_path):\n",
    "    \"\"\"\n",
    "    Move processed image to 'done' subdirectory\n",
    "    \"\"\"\n",
    "    filename = Path(image_path).name\n",
    "    destination = DONE_DIR / filename\n",
    "    \n",
    "    # Handle duplicate filenames\n",
    "    if destination.exists():\n",
    "        base = destination.stem\n",
    "        ext = destination.suffix\n",
    "        counter = 1\n",
    "        while destination.exists():\n",
    "            destination = DONE_DIR / f\"{base}_{counter}{ext}\"\n",
    "            counter += 1\n",
    "    \n",
    "    shutil.move(str(image_path), str(destination))\n",
    "    print(f\"  ✓ Moved to {destination}\")\n",
    "\n",
    "print(\"Move function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline function defined!\n",
      "\n",
      "Ready to run inference!\n",
      "Execute the next cell to process all images in the inference directory.\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Run Inference Pipeline\n",
    "# ========================\n",
    "def run_inference_pipeline():\n",
    "    \"\"\"\n",
    "    Main pipeline: Process all images in inference directory\n",
    "    \"\"\"\n",
    "    # Find all image files in inference directory\n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff']\n",
    "    image_files = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(list(INFERENCE_DIR.glob(f'*{ext}')))\n",
    "        #image_files.extend(list(INFERENCE_DIR.glob(f'*{ext.upper()}')))\n",
    "    \n",
    "    # Filter out files in subdirectories\n",
    "    image_files = [f for f in image_files if f.parent == INFERENCE_DIR]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in inference directory.\")\n",
    "        print(f\"Please place images in: {INFERENCE_DIR}\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"Found {len(image_files)} image(s) to process\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Process each image\n",
    "    for i, image_path in enumerate(image_files, 1):\n",
    "        try:\n",
    "            print(f\"\\n[{i}/{len(image_files)}] Processing {image_path.name}...\")\n",
    "            \n",
    "            # Run inference\n",
    "            results = process_image(image_path)\n",
    "            \n",
    "            # Save to Excel\n",
    "            save_results_to_excel(results)\n",
    "            \n",
    "            # Move to done\n",
    "            move_to_done(image_path)\n",
    "            \n",
    "            print(f\"  ✓ Completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ ERROR processing {image_path.name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Inference pipeline complete!\")\n",
    "    print(f\"Results saved to: {JOBS_FILE}\")\n",
    "    print(f\"Processed images moved to: {DONE_DIR}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "print(\"Pipeline function defined!\")\n",
    "print(\"\\nReady to run inference!\")\n",
    "print(\"Execute the next cell to process all images in the inference directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Found 3 image(s) to process\n",
      "======================================================================\n",
      "\n",
      "[1/3] Processing 011.png...\n",
      "\n",
      "Processing: 011.png\n",
      "  - Extracting CNN features...\n",
      "    CNN prediction: 1\n",
      "  - Extracting radiomics features...\n",
      "    Radiomics prediction: 1\n",
      "  - Extracting fusion features...\n",
      "    Fusion prediction: 2\n",
      "  ✓ Results saved to C:\\FeatureEx\\inference\\jobs.xlsx\n",
      "  ✓ Moved to C:\\FeatureEx\\inference\\done\\011.png\n",
      "  ✓ Completed successfully!\n",
      "\n",
      "[2/3] Processing 057.png...\n",
      "\n",
      "Processing: 057.png\n",
      "  - Extracting CNN features...\n",
      "    CNN prediction: 2\n",
      "  - Extracting radiomics features...\n",
      "    Radiomics prediction: 1\n",
      "  - Extracting fusion features...\n",
      "    Fusion prediction: 2\n",
      "  ✓ Results saved to C:\\FeatureEx\\inference\\jobs.xlsx\n",
      "  ✓ Moved to C:\\FeatureEx\\inference\\done\\057.png\n",
      "  ✓ Completed successfully!\n",
      "\n",
      "[3/3] Processing 111.png...\n",
      "\n",
      "Processing: 111.png\n",
      "  - Extracting CNN features...\n",
      "    CNN prediction: 3\n",
      "  - Extracting radiomics features...\n",
      "    Radiomics prediction: 1\n",
      "  - Extracting fusion features...\n",
      "    Fusion prediction: 2\n",
      "  ✓ Results saved to C:\\FeatureEx\\inference\\jobs.xlsx\n",
      "  ✓ Moved to C:\\FeatureEx\\inference\\done\\111.png\n",
      "  ✓ Completed successfully!\n",
      "\n",
      "======================================================================\n",
      "Inference pipeline complete!\n",
      "Results saved to: C:\\FeatureEx\\inference\\jobs.xlsx\n",
      "Processed images moved to: C:\\FeatureEx\\inference\\done\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# EXECUTE INFERENCE\n",
    "# ========================\n",
    "# Run this cell to process all images\n",
    "\n",
    "run_inference_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cnn_prediction</th>\n",
       "      <th>radiomic_prediction</th>\n",
       "      <th>fusion_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011.png</td>\n",
       "      <td>2025-11-11 12:22:15.869237</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>057.png</td>\n",
       "      <td>2025-11-11 12:22:16.614447</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.png</td>\n",
       "      <td>2025-11-11 12:22:17.538206</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>011.png</td>\n",
       "      <td>2025-11-11 12:54:53.429848</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>057.png</td>\n",
       "      <td>2025-11-11 12:54:54.108826</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.png</td>\n",
       "      <td>2025-11-11 12:54:54.894422</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>011.png</td>\n",
       "      <td>2025-11-11 15:29:12.096323</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>057.png</td>\n",
       "      <td>2025-11-11 15:29:13.583174</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111.png</td>\n",
       "      <td>2025-11-11 15:29:14.488394</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>011.png</td>\n",
       "      <td>2025-11-11 16:36:36.630580</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>057.png</td>\n",
       "      <td>2025-11-11 16:36:37.691735</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>111.png</td>\n",
       "      <td>2025-11-11 16:36:38.428789</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>011.png</td>\n",
       "      <td>2025-11-11 16:41:57.850102</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>057.png</td>\n",
       "      <td>2025-11-11 16:41:58.846808</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>111.png</td>\n",
       "      <td>2025-11-11 16:41:59.658024</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename                   timestamp  cnn_prediction  radiomic_prediction  \\\n",
       "0   011.png  2025-11-11 12:22:15.869237               1                  NaN   \n",
       "1   057.png  2025-11-11 12:22:16.614447               2                  NaN   \n",
       "2   111.png  2025-11-11 12:22:17.538206               3                  NaN   \n",
       "3   011.png  2025-11-11 12:54:53.429848               1                  NaN   \n",
       "4   057.png  2025-11-11 12:54:54.108826               2                  NaN   \n",
       "5   111.png  2025-11-11 12:54:54.894422               3                  NaN   \n",
       "6   011.png  2025-11-11 15:29:12.096323               1                  1.0   \n",
       "7   057.png  2025-11-11 15:29:13.583174               2                  1.0   \n",
       "8   111.png  2025-11-11 15:29:14.488394               3                  1.0   \n",
       "9   011.png  2025-11-11 16:36:36.630580               1                  1.0   \n",
       "10  057.png  2025-11-11 16:36:37.691735               2                  1.0   \n",
       "11  111.png  2025-11-11 16:36:38.428789               3                  1.0   \n",
       "12  011.png  2025-11-11 16:41:57.850102               1                  1.0   \n",
       "13  057.png  2025-11-11 16:41:58.846808               2                  1.0   \n",
       "14  111.png  2025-11-11 16:41:59.658024               3                  1.0   \n",
       "\n",
       "    fusion_prediction  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "5                 NaN  \n",
       "6                 2.0  \n",
       "7                 2.0  \n",
       "8                 2.0  \n",
       "9                 2.0  \n",
       "10                2.0  \n",
       "11                2.0  \n",
       "12                2.0  \n",
       "13                2.0  \n",
       "14                2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Scores (first 5 columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cnn_feature_1</th>\n",
       "      <th>cnn_feature_2</th>\n",
       "      <th>cnn_feature_3</th>\n",
       "      <th>cnn_feature_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>011.png</td>\n",
       "      <td>0.429978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263840</td>\n",
       "      <td>0.968519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>057.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.691453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.png</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219253</td>\n",
       "      <td>0.587153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>011.png</td>\n",
       "      <td>0.429978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263840</td>\n",
       "      <td>0.968519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>057.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.691453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.png</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219253</td>\n",
       "      <td>0.587153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>011.png</td>\n",
       "      <td>0.429978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263840</td>\n",
       "      <td>0.968519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>057.png</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.691453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111.png</td>\n",
       "      <td>0.034890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219253</td>\n",
       "      <td>0.587153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  cnn_feature_1  cnn_feature_2  cnn_feature_3  cnn_feature_4\n",
       "0  011.png       0.429978              0       0.263840       0.968519\n",
       "1  057.png       0.000000              0       0.211505       0.691453\n",
       "2  111.png       0.034890              0       0.219253       0.587153\n",
       "3  011.png       0.429978              0       0.263840       0.968519\n",
       "4  057.png       0.000000              0       0.211505       0.691453\n",
       "5  111.png       0.034890              0       0.219253       0.587153\n",
       "6  011.png       0.429978              0       0.263840       0.968519\n",
       "7  057.png       0.000000              0       0.211505       0.691453\n",
       "8  111.png       0.034890              0       0.219253       0.587153"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# View Results\n",
    "# ========================\n",
    "# View the predictions sheet\n",
    "print(\"Predictions:\")\n",
    "predictions_df = pd.read_excel(JOBS_FILE, sheet_name='predictions')\n",
    "display(predictions_df)\n",
    "\n",
    "print(\"\\nFeature Scores (first 5 columns):\")\n",
    "feature_scores_df = pd.read_excel(JOBS_FILE, sheet_name='feature_scores')\n",
    "display(feature_scores_df.iloc[:, :5])  # Show first 5 columns only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FeatureEx)",
   "language": "python",
   "name": "featureex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
