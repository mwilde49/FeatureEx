{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Medical Image Data Analysis with Compatibility Testing\n",
    "\n",
    "This notebook analyzes the 3D NIfTI dataset and performs comprehensive compatibility checks between paired images and labels.\n",
    "\n",
    "## Analysis includes:\n",
    "- Dataset size and file statistics\n",
    "- Image dimensions and channel information\n",
    "- Label classes and distribution\n",
    "- **Comprehensive image-label pair compatibility tests**\n",
    "- Memory analysis and batch sizing recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Import Libraries\n",
    "# ========================\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Setup Paths\n",
    "# ========================\n",
    "BASE_DIR = Path('C:/FeatureEx')\n",
    "IMAGES_DIR = BASE_DIR / 'imagesTr' / 'imagesTr'\n",
    "LABELS_DIR = BASE_DIR / 'labelsTr' / 'labelsTr'\n",
    "\n",
    "print(f\"Images directory: {IMAGES_DIR}\")\n",
    "print(f\"Labels directory: {LABELS_DIR}\")\n",
    "print(f\"\\nImages exist: {IMAGES_DIR.exists()}\")\n",
    "print(f\"Labels exist: {LABELS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Get File Lists\n",
    "# ========================\n",
    "image_files = sorted([f for f in IMAGES_DIR.glob('*.nii*')])\n",
    "label_files = sorted([f for f in LABELS_DIR.glob('*.nii*')])\n",
    "\n",
    "print(f\"Found {len(image_files)} image files\")\n",
    "print(f\"Found {len(label_files)} label files\")\n",
    "\n",
    "# Display first few files\n",
    "print(f\"\\nFirst 5 images:\")\n",
    "for f in image_files[:5]:\n",
    "    print(f\"  {f.name}\")\n",
    "\n",
    "print(f\"\\nFirst 5 labels:\")\n",
    "for f in label_files[:5]:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Analyze All Images\n",
    "# ========================\n",
    "print(f\"Analyzing all {len(image_files)} image files...\\n\")\n",
    "\n",
    "image_info = []\n",
    "\n",
    "for idx, img_path in enumerate(image_files, 1):\n",
    "    try:\n",
    "        img_nib = nib.load(img_path)\n",
    "        img_data = img_nib.get_fdata()\n",
    "        \n",
    "        info = {\n",
    "            'filename': img_path.name,\n",
    "            'shape': img_data.shape,\n",
    "            'dtype': img_data.dtype,\n",
    "            'min': img_data.min(),\n",
    "            'max': img_data.max(),\n",
    "            'mean': img_data.mean(),\n",
    "            'size_mb': img_path.stat().st_size / (1024**2)\n",
    "        }\n",
    "        image_info.append(info)\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Processed {idx}/{len(image_files)} images\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading {img_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully analyzed {len(image_info)} images\\n\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df_images = pd.DataFrame(image_info)\n",
    "print(\"Image Statistics:\")\n",
    "print(df_images.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Check Image Shape Consistency\n",
    "# ========================\n",
    "print(\"\\nImage Shape Consistency Check:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "unique_shapes = df_images['shape'].unique()\n",
    "print(f\"Number of unique image shapes: {len(unique_shapes)}\")\n",
    "print(f\"Shapes found:\")\n",
    "for shape in unique_shapes:\n",
    "    count = (df_images['shape'] == shape).sum()\n",
    "    print(f\"  {shape}: {count} images\")\n",
    "\n",
    "# Get most common shape\n",
    "most_common_shape = df_images['shape'].value_counts().index[0]\n",
    "print(f\"\\nMost common image shape: {most_common_shape}\")\n",
    "\n",
    "# Extract dimensions\n",
    "if len(most_common_shape) == 3:\n",
    "    depth, height, width = most_common_shape\n",
    "    num_channels = 1\n",
    "elif len(most_common_shape) == 4:\n",
    "    num_channels, depth, height, width = most_common_shape\n",
    "\n",
    "print(f\"\\nImage Configuration:\")\n",
    "print(f\"  Channels: {num_channels}\")\n",
    "print(f\"  Depth (Z): {depth}\")\n",
    "print(f\"  Height (Y): {height}\")\n",
    "print(f\"  Width (X): {width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Analyze All Labels\n",
    "# ========================\n",
    "print(f\"\\nAnalyzing all {len(label_files)} label files...\\n\")\n",
    "\n",
    "label_info = []\n",
    "all_unique_labels = set()\n",
    "\n",
    "for idx, label_path in enumerate(label_files, 1):\n",
    "    try:\n",
    "        label_nib = nib.load(label_path)\n",
    "        label_data = label_nib.get_fdata()\n",
    "        \n",
    "        unique_labels = np.unique(label_data)\n",
    "        all_unique_labels.update(unique_labels)\n",
    "        \n",
    "        info = {\n",
    "            'filename': label_path.name,\n",
    "            'shape': label_data.shape,\n",
    "            'dtype': label_data.dtype,\n",
    "            'min': label_data.min(),\n",
    "            'max': label_data.max(),\n",
    "            'unique_labels': len(unique_labels),\n",
    "            'size_mb': label_path.stat().st_size / (1024**2)\n",
    "        }\n",
    "        label_info.append(info)\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Processed {idx}/{len(label_files)} labels\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading {label_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully analyzed {len(label_info)} label files\\n\")\n",
    "\n",
    "df_labels = pd.DataFrame(label_info)\n",
    "print(\"Label Statistics:\")\n",
    "print(df_labels.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Check Label Shape Consistency\n",
    "# ========================\n",
    "print(\"\\nLabel Shape Consistency Check:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "unique_label_shapes = df_labels['shape'].unique()\n",
    "print(f\"Number of unique label shapes: {len(unique_label_shapes)}\")\n",
    "print(f\"Shapes found:\")\n",
    "for shape in unique_label_shapes:\n",
    "    count = (df_labels['shape'] == shape).sum()\n",
    "    print(f\"  {shape}: {count} labels\")\n",
    "\n",
    "# Label Analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Label Classes Found:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_unique_labels = sorted(list(all_unique_labels))\n",
    "print(f\"Unique labels across all files: {all_unique_labels}\")\n",
    "print(f\"Number of classes: {len(all_unique_labels)}\")\n",
    "\n",
    "print(f\"\\nLabel Mapping:\")\n",
    "for i, label in enumerate(all_unique_labels):\n",
    "    if label == 0:\n",
    "        print(f\"  {label} = Background\")\n",
    "    else:\n",
    "        print(f\"  {label} = Class {int(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Match Images and Labels\n",
    "# ========================\n",
    "print(\"\\nImage-Label Matching:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Number of images: {len(image_files)}\")\n",
    "print(f\"Number of labels: {len(label_files)}\")\n",
    "\n",
    "# Extract base names for matching\n",
    "image_basenames = {f.stem: f for f in image_files}\n",
    "label_basenames = {f.stem: f for f in label_files}\n",
    "\n",
    "# Check if names match\n",
    "matching_pairs = set(image_basenames.keys()) & set(label_basenames.keys())\n",
    "print(f\"\\nMatching image-label pairs: {len(matching_pairs)}/{len(image_files)}\")\n",
    "\n",
    "if len(matching_pairs) != len(image_files):\n",
    "    print(f\"\\n⚠️  WARNING: Not all images have matching labels!\")\n",
    "    missing_in_labels = set(image_basenames.keys()) - set(label_basenames.keys())\n",
    "    if missing_in_labels:\n",
    "        print(f\"   Images without labels: {len(missing_in_labels)}\")\n",
    "        print(f\"   Examples: {list(missing_in_labels)[:5]}\")\nelse:\n",
    "    print(f\"✓ All images have matching labels!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# COMPREHENSIVE COMPATIBILITY TEST\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMAGE-LABEL PAIR COMPATIBILITY TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "compatibility_results = []\n",
    "issues_found = []\n",
    "\n",
    "print(f\"\\nTesting {len(matching_pairs)} paired images and labels...\\n\")\n",
    "\n",
    "for idx, pair_name in enumerate(sorted(matching_pairs), 1):\n",
    "    try:\n",
    "        # Load image\n",
    "        img_path = image_basenames[pair_name]\n",
    "        img_nib = nib.load(img_path)\n",
    "        img_data = img_nib.get_fdata()\n",
    "        \n",
    "        # Load label\n",
    "        label_path = label_basenames[pair_name]\n",
    "        label_nib = nib.load(label_path)\n",
    "        label_data = label_nib.get_fdata()\n",
    "        \n",
    "        # Initialize results dict\n",
    "        result = {\n",
    "            'pair_name': pair_name,\n",
    "            'img_file': img_path.name,\n",
    "            'label_file': label_path.name,\n",
    "            'compatible': True,\n",
    "            'issues': []\n",
    "        }\n",
    "        \n",
    "        # Test 1: Shape compatibility\n",
    "        if img_data.shape != label_data.shape:\n",
    "            issue = f'Shape mismatch: Image {img_data.shape} vs Label {label_data.shape}'\n",
    "            result['issues'].append(issue)\n",
    "            result['compatible'] = False\n",
    "        \n",
    "        # Test 2: Data type compatibility\n",
    "        img_dtype = str(img_data.dtype)\n",
    "        label_dtype = str(label_data.dtype)\n",
    "        result['img_dtype'] = img_dtype\n",
    "        result['label_dtype'] = label_dtype\n",
    "        \n",
    "        # Test 3: Check for NaN or infinite values\n",
    "        img_has_nan = np.isnan(img_data).any()\n",
    "        img_has_inf = np.isinf(img_data).any()\n",
    "        label_has_nan = np.isnan(label_data).any()\n",
    "        label_has_inf = np.isinf(label_data).any()\n",
    "        \n",
    "        if img_has_nan:\n",
    "            result['issues'].append(f'Image has {np.isnan(img_data).sum()} NaN voxels')\n",
    "            result['compatible'] = False\n",
    "        if img_has_inf:\n",
    "            result['issues'].append(f'Image has {np.isinf(img_data).sum()} infinite voxels')\n",
    "            result['compatible'] = False\n",
    "        if label_has_nan:\n",
    "            result['issues'].append(f'Label has {np.isnan(label_data).sum()} NaN voxels')\n",
    "            result['compatible'] = False\n",
    "        if label_has_inf:\n",
    "            result['issues'].append(f'Label has {np.isinf(label_data).sum()} infinite voxels')\n",
    "            result['compatible'] = False\n",
    "        \n",
    "        # Test 4: Label values\n",
    "        label_values = np.unique(label_data)\n",
    "        result['label_values'] = sorted([int(x) for x in label_values])\n",
    "        \n",
    "        # Test 5: Spatial extent check\n",
    "        img_nonzero = np.count_nonzero(img_data)\n",
    "        label_nonzero = np.count_nonzero(label_data)\n",
    "        result['img_nonzero_voxels'] = int(img_nonzero)\n",
    "        result['label_nonzero_voxels'] = int(label_nonzero)\n",
    "        \n",
    "        if label_nonzero == 0:\n",
    "            result['issues'].append('Label is completely empty')\n",
    "            result['compatible'] = False\n",
    "        \n",
    "        # Test 6: Affine matrix compatibility\n",
    "        img_affine = img_nib.affine\n",
    "        label_affine = label_nib.affine\n",
    "        affine_match = np.allclose(img_affine, label_affine)\n",
    "        result['affine_match'] = bool(affine_match)\n",
    "        \n",
    "        # Store result\n",
    "        compatibility_results.append(result)\n",
    "        \n",
    "        if result['issues']:\n",
    "            issues_found.append((pair_name, result['issues']))\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            print(f'  Tested {idx}/{len(matching_pairs)} pairs')\n",
    "    except Exception as e:\n",
    "        print(f'  ERROR testing {pair_name}: {e}')                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "        compatibility_results.append({\n",
    "            'pair_name': pair_name,\n",
    "            'compatible': False,\n",
    "            'issues': [str(e)]\n",
    "        })\n",
    "        issues_found.append((pair_name, [str(e)]))\n",
    "\n",
    "print(f'\\nCompatibility testing complete!')\n",
    "print(f'Total pairs tested: {len(compatibility_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# COMPATIBILITY TEST RESULTS\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPATIBILITY TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "compatible_count = sum(1 for r in compatibility_results if r['compatible'])\n",
    "incompatible_count = len(compatibility_results) - compatible_count\n",
    "\n",
    "print(f\"\\nCompatible pairs: {compatible_count}/{len(compatibility_results)}\")\n",
    "print(f\"Incompatible pairs: {incompatible_count}/{len(compatibility_results)}\")\n",
    "\n",
    "if issues_found:\n",
    "    print(f\"\\n⚠️  ISSUES FOUND ({len(issues_found)} pairs with problems):\")\n",
    "    print(\"-\"*70)\n",
    "    for pair_name, issues in issues_found[:10]:\n",
    "        print(f\"\\n{pair_name}:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    if len(issues_found) > 10:\n",
    "        print(f\"\\n... and {len(issues_found) - 10} more pairs with issues\")\n",
    "else:\n",
    "    print(f\"\\n✅ ALL PAIRS ARE COMPATIBLE!\")\n",
    "\n",
    "# Summary statistics\n",
    "df_compat = pd.DataFrame(compatibility_results)\n",
    "print(f\"\\nCompatibility Summary:\")\n",
    "print(f\"  Total tested: {len(df_compat)}\")\n",
    "print(f\"  Compatible: {df_compat['compatible'].sum()}\")\n",
    "print(f\"  Incompatible: {(~df_compat['compatible']).sum()}\")\n",
    "print(f\"  Success rate: {(df_compat['compatible'].sum() / len(df_compat)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# DETAILED COMPATIBILITY REPORT\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED COMPATIBILITY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show unique issues\n",
    "all_issues = []\n",
    "for pair_name, issues in issues_found:\n",
    "    all_issues.extend(issues)\n",
    "\n",
    "if all_issues:\n",
    "    issue_counts = Counter(all_issues)\n",
    "    print(f\"\\nIssue Summary:\")\n",
    "    for issue, count in issue_counts.most_common():\n",
    "        print(f\"  - {count}x: {issue[:70]}\")\n",
    "\n",
    "# Data type consistency\n",
    "print(f\"\\nData Type Consistency:\")\n",
    "img_dtypes = df_compat['img_dtype'].value_counts()\n",
    "label_dtypes = df_compat['label_dtype'].value_counts()\n",
    "print(f\"  Image types: {dict(img_dtypes)}\")\n",
    "print(f\"  Label types: {dict(label_dtypes)}\")\n",
    "\n",
    "# Affine matrix consistency\n",
    "if 'affine_match' in df_compat.columns:\n",
    "    affine_counts = df_compat['affine_match'].value_counts()\n",
    "    print(f\"\\nAffine Matrix Compatibility:\")\n",
    "    print(f\"  Matching: {affine_counts.get(True, 0)}\")\n",
    "    print(f\"  Not matching: {affine_counts.get(False, 0)}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "if incompatible_count == 0:\n",
    "    print(f\"✅ DATASET IS READY FOR PROCESSING\")\n",
    "    print(f\"   All {len(df_compat)} image-label pairs are compatible\")\n",
    "else:\n",
    "    print(f\"⚠️  DATASET REQUIRES PREPROCESSING\")\n",
    "    print(f\"   {incompatible_count} pairs have compatibility issues\")\n",
    "    print(f\"   Recommend fixing before pipeline training\")\n",
    "print(f\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# FINAL CONFIGURATION SUMMARY\n",
    "# ========================\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3D PIPELINE CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "config = {\n",
    "    'dataset': {\n",
    "        'num_images': len(image_files),\n",
    "        'num_labels': len(label_files),\n",
    "        'matching_pairs': len(matching_pairs),\n",
    "        'compatible_pairs': compatible_count,\n",
    "        'incompatible_pairs': incompatible_count,\n",
    "    },\n",
    "    'image_dimensions': {\n",
    "        'channels': num_channels,\n",
    "        'depth': depth,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "    },\n",
    "    'labels': {\n",
    "        'unique_labels': list(all_unique_labels),\n",
    "        'num_classes': len(all_unique_labels),\n",
    "        'has_background': 0 in all_unique_labels,\n",
    "    },\n",
    "    'data_quality': {\n",
    "        'all_compatible': incompatible_count == 0,\n",
    "        'compatibility_rate': round((compatible_count / len(compatibility_results)) * 100, 1),\n",
    "    }\n",
    "}\n",
    "\n",
    "for section, values in config.items():\n",
    "    print(f\"{section.upper()}:\")\n",
    "    for key, value in values.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# Save configuration\n",
    "config_path = BASE_DIR / '3d_dataset_config.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\nConfiguration saved to: {config_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FeatureEx)",
   "language": "python",
   "name": "featureex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/application",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
