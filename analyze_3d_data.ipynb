{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Medical Image Data Analysis\n",
    "\n",
    "This notebook analyzes the 3D NIfTI dataset to extract all necessary information for pipeline configuration.\n",
    "We will determine:\n",
    "- Number of images and labels\n",
    "- Image dimensions (depth, height, width)\n",
    "- Number of channels\n",
    "- Number of classes and label mapping\n",
    "- Data types and value ranges\n",
    "- Memory requirements\n",
    "- Consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Import Libraries\n",
    "# ========================\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Setup Paths\n",
    "# ========================\n",
    "BASE_DIR = Path('C:/FeatureEx')\n",
    "IMAGES_DIR = BASE_DIR / 'imagesTr' / 'imagesTr'\n",
    "LABELS_DIR = BASE_DIR / 'labelsTr' / 'labelsTr'\n",
    "\n",
    "print(f\"Images directory: {IMAGES_DIR}\")\n",
    "print(f\"Labels directory: {LABELS_DIR}\")\n",
    "print(f\"\\nImages exist: {IMAGES_DIR.exists()}\")\n",
    "print(f\"Labels exist: {LABELS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Get File Lists\n",
    "# ========================\n",
    "image_files = sorted([f for f in IMAGES_DIR.glob('*.nii*')])\n",
    "label_files = sorted([f for f in LABELS_DIR.glob('*.nii*')])\n",
    "\n",
    "print(f\"Found {len(image_files)} image files\")\n",
    "print(f\"Found {len(label_files)} label files\")\n",
    "\n",
    "# Display first few files\n",
    "print(f\"\\nFirst 5 images:\")\n",
    "for f in image_files[:5]:\n",
    "    print(f\"  {f.name}\")\n",
    "\n",
    "print(f\"\\nFirst 5 labels:\")\n",
    "for f in label_files[:5]:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Analyze First Image\n",
    "# ========================\n",
    "print(\"Analyzing first image file...\\n\")\n",
    "\n",
    "first_image_path = image_files[0]\n",
    "print(f\"File: {first_image_path.name}\")\n",
    "print(f\"Size: {first_image_path.stat().st_size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Load with nibabel\n",
    "img_nib = nib.load(first_image_path)\n",
    "img_data = img_nib.get_fdata()\n",
    "\n",
    "print(f\"\\nNIfTI Header Information:\")\n",
    "print(f\"  Shape: {img_nib.shape}\")\n",
    "print(f\"  Data type: {img_data.dtype}\")\n",
    "print(f\"  Affine matrix shape: {img_nib.affine.shape}\")\n",
    "print(f\"  Voxel size: {nib.aff2axcodes(img_nib.affine)}\")\n",
    "\n",
    "print(f\"\\nData Array Information:\")\n",
    "print(f\"  Array shape: {img_data.shape}\")\n",
    "print(f\"  Array dtype: {img_data.dtype}\")\n",
    "print(f\"  Min value: {img_data.min():.6f}\")\n",
    "print(f\"  Max value: {img_data.max():.6f}\")\n",
    "print(f\"  Mean value: {img_data.mean():.6f}\")\n",
    "print(f\"  Std value: {img_data.std():.6f}\")\n",
    "\n",
    "# Determine dimensions\n",
    "if len(img_data.shape) == 3:\n",
    "    depth, height, width = img_data.shape\n",
    "    num_channels = 1\n",
    "    print(f\"\\nImage Configuration:\")\n",
    "    print(f\"  Channels: {num_channels}\")\n",
    "    print(f\"  Depth (Z): {depth}\")\n",
    "    print(f\"  Height (Y): {height}\")\n",
    "    print(f\"  Width (X): {width}\")\nelif len(img_data.shape) == 4:\n",
    "    num_channels, depth, height, width = img_data.shape\n",
    "    print(f\"\\nImage Configuration:\")\n",
    "    print(f\"  Channels: {num_channels}\")\n",
    "    print(f\"  Depth (Z): {depth}\")\n",
    "    print(f\"  Height (Y): {height}\")\n",
    "    print(f\"  Width (X): {width}\")\nelse:\n",
    "    print(f\"  Unexpected shape: {img_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Analyze All Images\n",
    "# ========================\n",
    "print(f\"Analyzing all {len(image_files)} image files...\\n\")\n",
    "\n",
    "image_info = []\n",
    "\n",
    "for idx, img_path in enumerate(image_files, 1):\n",
    "    try:\n",
    "        img_nib = nib.load(img_path)\n",
    "        img_data = img_nib.get_fdata()\n",
    "        \n",
    "        info = {\n",
    "            'filename': img_path.name,\n",
    "            'shape': img_data.shape,\n",
    "            'dtype': img_data.dtype,\n",
    "            'min': img_data.min(),\n",
    "            'max': img_data.max(),\n",
    "            'mean': img_data.mean(),\n",
    "            'size_mb': img_path.stat().st_size / (1024**2)\n",
    "        }\n",
    "        image_info.append(info)\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Processed {idx}/{len(image_files)} images\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading {img_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully analyzed {len(image_info)} images\\n\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df_images = pd.DataFrame(image_info)\n",
    "print(\"Image Statistics:\")\n",
    "print(df_images.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Check Shape Consistency\n",
    "# ========================\n",
    "print(\"\\nShape Consistency Check:\")\nprint(\"=\"*70)\n",
    "\n",
    "# Get unique shapes\n",
    "unique_shapes = df_images['shape'].unique()\n",
    "print(f\"Number of unique shapes: {len(unique_shapes)}\")\n",
    "print(f\"Shapes found:\")\nfor shape in unique_shapes:\n",
    "    count = (df_images['shape'] == shape).sum()\n",
    "    print(f\"  {shape}: {count} images\")\n",
    "\n",
    "# Most common shape\n",
    "most_common_shape = df_images['shape'].value_counts().index[0]\n",
    "print(f\"\\nMost common shape: {most_common_shape}\")\n",
    "\n",
    "# Get dimensions from most common shape\n",
    "if len(most_common_shape) == 3:\n",
    "    depth, height, width = most_common_shape\n",
    "    num_channels = 1\nelif len(most_common_shape) == 4:\n",
    "    num_channels, depth, height, width = most_common_shape\n",
    "\n",
    "print(f\"\\n3D Configuration:\")\nprint(f\"  Channels: {num_channels}\")\nprint(f\"  Depth (Z): {depth}\")\nprint(f\"  Height (Y): {height}\")\nprint(f\"  Width (X): {width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Analyze All Labels\n",
    "# ========================\n",
    "print(f\"\\nAnalyzing all {len(label_files)} label files...\\n\")\n",
    "\n",
    "label_info = []\n",
    "all_unique_labels = set()\n",
    "\n",
    "for idx, label_path in enumerate(label_files, 1):\n",
    "    try:\n",
    "        label_nib = nib.load(label_path)\n",
    "        label_data = label_nib.get_fdata()\n",
    "        \n",
    "        # Get unique labels in this file\n",
    "        unique_labels = np.unique(label_data)\n",
    "        all_unique_labels.update(unique_labels)\n",
    "        \n",
    "        info = {\n",
    "            'filename': label_path.name,\n",
    "            'shape': label_data.shape,\n",
    "            'dtype': label_data.dtype,\n",
    "            'min': label_data.min(),\n",
    "            'max': label_data.max(),\n",
    "            'unique_labels': len(unique_labels),\n",
    "            'size_mb': label_path.stat().st_size / (1024**2)\n",
    "        }\n",
    "        label_info.append(info)\n",
    "        \n",
    "        if idx % 10 == 0:\n",
    "            print(f\"  Processed {idx}/{len(label_files)} labels\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading {label_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully analyzed {len(label_info)} label files\\n\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_labels = pd.DataFrame(label_info)\n",
    "print(\"Label Statistics:\")\nprint(df_labels.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Label Analysis\n",
    "# ========================\n",
    "print(\"\\nLabel Classes Found:\")\nprint(\"=\"*70)\n",
    "\n",
    "all_unique_labels = sorted(list(all_unique_labels))\n",
    "print(f\"Unique labels across all files: {all_unique_labels}\")\nprint(f\"Number of classes: {len(all_unique_labels)}\")\n",
    "\n",
    "# Label mapping\nprint(f\"\\nLabel Mapping:\")\nfor i, label in enumerate(all_unique_labels):\n",
    "    if label == 0:\n",
    "        print(f\"  {label} = Background\")\n",
    "    else:\n",
    "        print(f\"  {label} = Class {int(label)}\")\n",
    "\n",
    "# Count frequency\nprint(f\"\\nLabel Distribution Across Dataset:\")\nlabel_counter = Counter()\n",
    "\nfor label_path in label_files:\n",
    "    try:\n",
    "        label_nib = nib.load(label_path)\n",
    "        label_data = label_nib.get_fdata()\n",
    "        unique_labels_in_file = np.unique(label_data)\n",
    "        for label in unique_labels_in_file:\n",
    "            label_counter[int(label)] += 1\n",
    "    except:\n",
    "        pass\n",
    "\nfor label in sorted(label_counter.keys()):\n",
    "    count = label_counter[label]\n",
    "    pct = (count / len(label_files)) * 100\n",
    "    if label == 0:\n",
    "        print(f\"  Background (0): {count}/{len(label_files)} files ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  Class {label}: {count}/{len(label_files)} files ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Check Image-Label Matching\n",
    "# ========================\n",
    "print(\"\\nImage-Label Matching:\")\nprint(\"=\"*70)\n",
    "\n",
    "print(f\"Number of images: {len(image_files)}\")\nprint(f\"Number of labels: {len(label_files)}\")\n",
    "\n",
    "# Extract base names for matching\nimage_basenames = {f.stem: f for f in image_files}\nlabel_basenames = {f.stem: f for f in label_files}\n",
    "\nprint(f\"\\nImage basenames (first 5):\")\nfor i, name in enumerate(list(image_basenames.keys())[:5]):\n",
    "    print(f\"  {name}\")\n",
    "\nprint(f\"\\nLabel basenames (first 5):\")\nfor i, name in enumerate(list(label_basenames.keys())[:5]):\n",
    "    print(f\"  {name}\")\n",
    "\n",
    "# Check if names match\nmatching_pairs = set(image_basenames.keys()) & set(label_basenames.keys())\nprint(f\"\\nMatching image-label pairs: {len(matching_pairs)}/{len(image_files)}\")\n",
    "\nif len(matching_pairs) != len(image_files):\n",
    "    print(f\"\\n⚠️  WARNING: Not all images have matching labels!\")\n",
    "    missing_in_labels = set(image_basenames.keys()) - set(label_basenames.keys())\n",
    "    if missing_in_labels:\n",
    "        print(f\"   Images without labels: {len(missing_in_labels)}\")\n",
    "        print(f\"   Examples: {list(missing_in_labels)[:5]}\")\n",
    "else:\n",
    "    print(f\"✓ All images have matching labels!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Memory Analysis\n",
    "# ========================\n",
    "print(\"\\nMemory Analysis:\")\nprint(\"=\"*70)\n",
    "\n",
    "# Single image memory\nif num_channels == 1:\n",
    "    single_image_bytes = depth * height * width * 4  # assuming float32\nelse:\n",
    "    single_image_bytes = num_channels * depth * height * width * 4\n",
    "\nsingle_image_mb = single_image_bytes / (1024**2)\ntotal_dataset_mb = single_image_mb * len(image_files)\ntotal_dataset_gb = total_dataset_mb / 1024\n",
    "\nprint(f\"Per-image memory (float32):\")\nprint(f\"  Bytes: {single_image_bytes:,}\")\nprint(f\"  MB: {single_image_mb:.2f}\")\n",
    "\nprint(f\"\\nTotal dataset memory:\")\nprint(f\"  MB: {total_dataset_mb:.2f}\")\nprint(f\"  GB: {total_dataset_gb:.2f}\")\n",
    "\nprint(f\"\\nEstimated batch memory (batch_size=2):\")\nbatch_size = 2\nbatch_mb = single_image_mb * batch_size\nprint(f\"  MB: {batch_mb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# CONFIGURATION SUMMARY\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*70)\nprint(\"3D PIPELINE CONFIGURATION SUMMARY\")\nprint(\"=\"*70 + \"\\n\")\n",
    "\nconfig = {\n",
    "    'dataset': {\n",
    "        'num_images': len(image_files),\n",
    "        'num_labels': len(label_files),\n",
    "        'matching_pairs': len(matching_pairs),\n",
    "    },\n",
    "    'image_dimensions': {\n",
    "        'channels': num_channels,\n",
    "        'depth': depth,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'shape': f\"({num_channels}, {depth}, {height}, {width})\" if num_channels > 1 else f\"({depth}, {height}, {width})\",\n",
    "    },\n",
    "    'labels': {\n",
    "        'unique_labels': list(all_unique_labels),\n",
    "        'num_classes': len(all_unique_labels),\n",
    "        'has_background': 0 in all_unique_labels,\n",
    "    },\n",
    "    'data_types': {\n",
    "        'image_dtype': str(df_images['dtype'].iloc[0]),\n",
    "        'label_dtype': str(df_labels['dtype'].iloc[0]),\n",
    "    },\n",
    "    'memory': {\n",
    "        'per_image_mb': round(single_image_mb, 2),\n",
    "        'total_dataset_mb': round(total_dataset_mb, 2),\n",
    "        'total_dataset_gb': round(total_dataset_gb, 2),\n",
    "    }\n",
    "}\n",
    "\nfor section, values in config.items():\n",
    "    print(f\"{section.upper()}:\")\n",
    "    for key, value in values.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Export Configuration\n",
    "# ========================\n",
    "import json\n",
    "\n",
    "config_output = {\n",
    "    'dataset_info': {\n",
    "        'num_images': int(len(image_files)),\n",
    "        'num_labels': int(len(label_files)),\n",
    "        'matching_pairs': int(len(matching_pairs)),\n",
    "    },\n",
    "    'image_dimensions': {\n",
    "        'channels': int(num_channels),\n",
    "        'depth': int(depth),\n",
    "        'height': int(height),\n",
    "        'width': int(width),\n",
    "    },\n",
    "    'labels': {\n",
    "        'unique_labels': [int(x) for x in all_unique_labels],\n",
    "        'num_classes': int(len(all_unique_labels)),\n",
    "        'has_background': int(0 in all_unique_labels),\n",
    "    },\n",
    "    'data_types': {\n",
    "        'image_dtype': str(df_images['dtype'].iloc[0]),\n",
    "        'label_dtype': str(df_labels['dtype'].iloc[0]),\n",
    "    },\n",
    "    'memory_mb': {\n",
    "        'per_image': round(single_image_mb, 2),\n",
    "        'total_dataset': round(total_dataset_mb, 2),\n",
    "    }\n",
    "}\n",
    "\n# Save as JSON\nconfig_path = BASE_DIR / '3d_dataset_config.json'\nwith open(config_path, 'w') as f:\n",
    "    json.dump(config_output, f, indent=2)\n",
    "\nprint(f\"Configuration saved to: {config_path}\")\nprint(f\"\\nConfiguration (JSON):\")\nprint(json.dumps(config_output, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Sample a Few Images\n",
    "# ========================\n",
    "print(\"\\nDetailed Sample Analysis:\")\nprint(\"=\"*70)\n",
    "\nfor i in range(min(3, len(image_files))):\n",
    "    img_path = image_files[i]\n",
    "    print(f\"\\nImage {i+1}: {img_path.name}\")\n",
    "    \n",
    "    img_nib = nib.load(img_path)\n",
    "    img_data = img_nib.get_fdata()\n",
    "    \n",
    "    print(f\"  Shape: {img_data.shape}\")\n",
    "    print(f\"  DType: {img_data.dtype}\")\n",
    "    print(f\"  Range: [{img_data.min():.4f}, {img_data.max():.4f}]\")\n",
    "    print(f\"  Mean: {img_data.mean():.4f}, Std: {img_data.std():.4f}\")\n",
    "    \n",
    "    # Check for matching label\n",
    "    label_name = img_path.stem\n",
    "    matching_label = LABELS_DIR / f\"{label_name}.nii\"\n",
    "    if not matching_label.exists():\n",
    "        matching_label = LABELS_DIR / f\"{label_name}.nii.gz\"\n",
    "    \n",
    "    if matching_label.exists():\n",
    "        label_nib = nib.load(matching_label)\n",
    "        label_data = label_nib.get_fdata()\n",
    "        print(f\"  Label file: {matching_label.name}\")\n",
    "        print(f\"  Label shape: {label_data.shape}\")\n",
    "        print(f\"  Label DType: {label_data.dtype}\")\n",
    "        print(f\"  Unique labels: {sorted(np.unique(label_data).astype(int).tolist())}\")\n",
    "    else:\n",
    "        print(f\"  Label file: NOT FOUND\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FeatureEx)",
   "language": "python",
   "name": "featureex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-application",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
